{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision as tv\n",
    "\n",
    "from torchvision.models.detection import ssd300_vgg16\n",
    "\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "np.random.seed(21)\n",
    "torch.manual_seed(21);\n",
    "\n",
    "test = [0,2,14,17,28,29,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCCDDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root='BCCD/', trans=None):\n",
    "        super()\n",
    "        self.root = root\n",
    "        self.pds = pd.read_csv('./BCCD/test.csv')\n",
    "        self.clases = ['Bachground'] + list(self.pds.cell_type.unique())\n",
    "        self.clases_idx = {w: i for i, w in enumerate(self.clases)}\n",
    "        self.transforms = tv.transforms.Compose([\n",
    "               # tv.transforms.Resize([300, 300]),\n",
    "                tv.transforms.ToTensor(),\n",
    "                tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "                ])\n",
    "        self.imgs = self.pds.filename.unique()\n",
    "        \n",
    "    def get_image(self, idx):\n",
    "        filename = self.imgs[idx]\n",
    "        img = Image.open(os.path.join(self.root+'JPEGImages',filename)).convert(\"RGB\")\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.imgs[idx]\n",
    "        img = Image.open(os.path.join(self.root+'JPEGImages',filename)).convert(\"RGB\")\n",
    "        x = self.pds\n",
    "        x = x[x.filename == filename]\n",
    "        x = x[x.xmin < x.xmax]\n",
    "        x = x[x.ymin < x.ymax]\n",
    "        x = np.array(x)\n",
    "        for i in range(len(x)):\n",
    "            x[i,1]=self.clases_idx[x[i,1]]\n",
    "        labels  = torch.as_tensor(x[:,1].astype(int), dtype=torch.int64).to(device)\n",
    "        boxes = torch.as_tensor(x[:,[2,4,3,5]].astype(float), dtype=torch.float32).to(device)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((len(x),), dtype=torch.int64)\n",
    "\n",
    "\n",
    "        img = self.transforms(img).to(device)\n",
    "\n",
    "        return img, {'boxes':boxes, 'labels':labels}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ricarojas/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ricarojas/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SSD300_VGG16_Weights.COCO_V1`. You can also use `weights=SSD300_VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = ssd300_vgg16(pretrained = True).to(device) # weights='DEFAULT',\n",
    "ds=BCCDDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%2dm %2ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/BCCD/JPEGImages/BloodImage_00073.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(perm):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m p,t \u001b[39m=\u001b[39m ds[perm[i]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m pp\u001b[39m.\u001b[39mappend(p)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m tt\u001b[39m.\u001b[39mappend(t)\n",
      "\u001b[1;32m/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb Cell 6\u001b[0m in \u001b[0;36mBCCDDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs[idx]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mJPEGImages\u001b[39;49m\u001b[39m'\u001b[39;49m,filename))\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpds\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     x \u001b[39m=\u001b[39m x[x\u001b[39m.\u001b[39mfilename \u001b[39m==\u001b[39m filename]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/PIL/Image.py:2953\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2950\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[1;32m   2952\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[0;32m-> 2953\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2954\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2956\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/BCCD/JPEGImages/BloodImage_00073.jpg'"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "start = time.time()\n",
    "eps = 20\n",
    "trn=list(set(range(len(ds)))-set(test))\n",
    "for ep in range(eps):\n",
    "    perm = np.random.permutation(trn)\n",
    "    i = 0\n",
    "    l0=0\n",
    "    l1=0\n",
    "    l2=0\n",
    "    ln=0\n",
    "    while True:\n",
    "        pp=[]\n",
    "        tt=[]\n",
    "        trainer.zero_grad()\n",
    "        for j in range(50):\n",
    "            if i >= len(perm):\n",
    "                break\n",
    "            p,t = ds[perm[i]]\n",
    "            pp.append(p)\n",
    "            tt.append(t)\n",
    "            i +=1\n",
    "        pred = model(pp,tt)\n",
    "        loss = pred['bbox_regression'] * pred['bbox_regression'] * 20 + pred['classification']\n",
    "        loss.backward()\n",
    "        trainer.step()  \n",
    "        l1+=pred['bbox_regression'].item()\n",
    "        l2+=pred['classification'].item()\n",
    "        l0+=loss.item()\n",
    "        ln+=1\n",
    "        if i >= len(perm):\n",
    "            break\n",
    "    pc = (ep + 1) / eps \n",
    "    print('%s (%2d %3d%%) %8.4f %8.4f %8.4f' % \n",
    "          (timeSince(start, pc),ep,pc*100,l0/ln,l1/ln,l2/ln))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/BCCD/JPEGImages/BloodImage_000000.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m test:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     p,t \u001b[39m=\u001b[39m ds[i]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model([p])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     img \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mget_image(i)\n",
      "\u001b[1;32m/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb Cell 7\u001b[0m in \u001b[0;36mBCCDDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs[idx]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mJPEGImages\u001b[39;49m\u001b[39m'\u001b[39;49m,filename))\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpds\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ricarojas/Documents/git/project_quatro/test-train.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     x \u001b[39m=\u001b[39m x[x\u001b[39m.\u001b[39mfilename \u001b[39m==\u001b[39m filename]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/PIL/Image.py:2953\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2950\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[1;32m   2952\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[0;32m-> 2953\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2954\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2956\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/BCCD/JPEGImages/BloodImage_000000.jpg'"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i in test:\n",
    "    p,t = ds[i]\n",
    "    outputs = model([p])\n",
    "    img = ds.get_image(i)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    classes = outputs[0]['labels'].cpu().numpy()\n",
    "    scores = outputs[0]['scores'].detach().cpu().numpy()\n",
    "    boxes = outputs[0]['boxes'].detach().cpu().numpy()\n",
    "\n",
    "    for i,box in enumerate(boxes):\n",
    "        if scores[i] > 0.5 :\n",
    "            c = classes[i]\n",
    "            c = c if c < 4 else 0\n",
    "            cl = ['black','red','green','blue']\n",
    "            draw.rectangle(xy=box.tolist(), outline=cl[c])\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
